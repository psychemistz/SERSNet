{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utils\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "## Classical Learner\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset Parameter Setting\"\"\"\n",
    "\"\"\"Load Dataset\"\"\"\n",
    "cdcl2_b1_dset = pd.read_csv(\"C:/Users/sypark/Desktop/Projects/w_MinSeok/1SERSNet/2data/_preprocessed/sersnet_cdcl2_b1_bn_bl_corrected.csv\")\n",
    "cdcl2_b2_dset = pd.read_csv(\"C:/Users/sypark/Desktop/Projects/w_MinSeok/1SERSNet/2data/_preprocessed/sersnet_cdcl2_b2_bn_bl_corrected.csv\")\n",
    "\n",
    "pbcl2_b1_dset = pd.read_csv(\"C:/Users/sypark/Desktop/Projects/w_MinSeok/1SERSNet/2data/_preprocessed/sersnet_pbcl2_b1_bn_bl_corrected.csv\")\n",
    "pbcl2_b2_dset = pd.read_csv(\"C:/Users/sypark/Desktop/Projects/w_MinSeok/1SERSNet/2data/_preprocessed/sersnet_pbcl2_b2_bn_bl_corrected.csv\")\n",
    "\n",
    "pbno32_b1_dset = pd.read_csv(\"C:/Users/sypark/Desktop/Projects/w_MinSeok/1SERSNet/2data/_preprocessed/sersnet_pbno32_b1_bn_bl_corrected.csv\")\n",
    "pbno32_b2_dset = pd.read_csv(\"C:/Users/sypark/Desktop/Projects/w_MinSeok/1SERSNet/2data/_preprocessed/sersnet_pbno32_b2_bn_bl_corrected.csv\")\n",
    "\n",
    "\n",
    "\"\"\"Set Output Path\"\"\"\n",
    "fileout = \"C:/Users/sypark/Desktop/Projects/w_MinSeok/1SERSNet/3results/HM_Classification/raw_data/baseline_binary_hm_model_output_b2_to_b1_bn_bl_corrected_batch_combine.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcl2_b1_dset = pd.concat([pd.DataFrame(cdcl2_b1_dset.iloc[:, 3]).rename(columns={'Concentration_uM': 'label'}), \n",
    "                           cdcl2_b1_dset.iloc[:, 5:]], axis=1)\n",
    "cdcl2_b2_dset = pd.concat([pd.DataFrame(cdcl2_b2_dset.iloc[:, 3]).rename(columns={'Concentration_uM': 'label'}), \n",
    "                           cdcl2_b2_dset.iloc[:, 5:]], axis=1)\n",
    "cdcl2_all_dset = pd.concat([cdcl2_b1_dset, cdcl2_b2_dset], axis=0).reset_index(drop=True)\n",
    "\n",
    "pbcl2_b1_dset = pd.concat([pd.DataFrame(pbcl2_b1_dset.iloc[:, 3]).rename(columns={'Concentration_uM': 'label'}), \n",
    "                           pbcl2_b1_dset.iloc[:, 5:]], axis=1)\n",
    "pbcl2_b2_dset = pd.concat([pd.DataFrame(pbcl2_b2_dset.iloc[:, 3]).rename(columns={'Concentration_uM': 'label'}), \n",
    "                           pbcl2_b2_dset.iloc[:, 5:]], axis=1)\n",
    "pbcl2_all_dset = pd.concat([pbcl2_b1_dset, pbcl2_b2_dset], axis=0).reset_index(drop=True)\n",
    "\n",
    "pbno32_b1_dset = pd.concat([pd.DataFrame(pbno32_b1_dset.iloc[:, 3]).rename(columns={'Concentration_uM': 'label'}), \n",
    "                            pbno32_b1_dset.iloc[:, 5:]], axis=1)\n",
    "pbno32_b2_dset = pd.concat([pd.DataFrame(pbno32_b2_dset.iloc[:, 3]).rename(columns={'Concentration_uM': 'label'}),\n",
    "                            pbno32_b2_dset.iloc[:, 5:]], axis=1)\n",
    "pbno32_all_dset = pd.concat([pbno32_b1_dset, pbno32_b2_dset], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CdCl2 Dataset\n",
    "tmp1 = np.array(cdcl2_b1_dset.iloc[:,0] <=1e-2, dtype='int64')\n",
    "tmp2 = np.array(cdcl2_b2_dset.iloc[:,0] <=1e-2, dtype='int64')\n",
    "\n",
    "cdcl2_b1_dset = pd.concat([pd.DataFrame(tmp1).rename(columns={0:'label'}), cdcl2_b1_dset.iloc[:,1:]], axis=1)\n",
    "cdcl2_b2_dset = pd.concat([pd.DataFrame(tmp2).rename(columns={0:'label'}), cdcl2_b2_dset.iloc[:,1:]], axis=1)\n",
    "cdcl2_dset = pd.concat([cdcl2_b1_dset, cdcl2_b2_dset], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pbcl2 Dataset\n",
    "tmp1 = np.array(pbcl2_b1_dset.iloc[:,0] <=1e-2, dtype='int64')\n",
    "tmp2 = np.array(pbcl2_b2_dset.iloc[:,0] <=1e-2, dtype='int64')\n",
    "\n",
    "pbcl2_b1_dset = pd.concat([pd.DataFrame(tmp1).rename(columns={0:'label'}), pbcl2_b1_dset.iloc[:,1:]], axis=1)\n",
    "pbcl2_b2_dset = pd.concat([pd.DataFrame(tmp2).rename(columns={0:'label'}), pbcl2_b2_dset.iloc[:,1:]], axis=1)\n",
    "pbcl2_dset = pd.concat([pbcl2_b1_dset, pbcl2_b2_dset], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pb(NO3)2 Dataset\n",
    "tmp1 = np.array(pbno32_b1_dset.iloc[:,0] <=1e-2, dtype='int64')\n",
    "tmp2 = np.array(pbno32_b2_dset.iloc[:,0] <=1e-2, dtype='int64')\n",
    "\n",
    "pbno32_b1_dset = pd.concat([pd.DataFrame(tmp1).rename(columns={0:'label'}), pbno32_b1_dset.iloc[:,1:]], axis=1)\n",
    "pbno32_b2_dset = pd.concat([pd.DataFrame(tmp2).rename(columns={0:'label'}), pbno32_b2_dset.iloc[:,1:]], axis=1)\n",
    "pbno32_dset = pd.concat([pbno32_b1_dset, pbno32_b2_dset], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdcl2_dset = cdcl2_dset.iloc[:,:-1]\n",
    "pbcl2_dset = pbcl2_dset.iloc[:,:-1]\n",
    "pbno32_dset = pbno32_dset.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cdcl2_dset = cdcl2_dset.iloc[:, 1:].to_numpy(dtype='float32')\n",
    "y_cdcl2_dset = cdcl2_dset.iloc[:,0].to_numpy(dtype='int64') \n",
    "\n",
    "X_pbcl2_dset = pbcl2_dset.iloc[:, 1:].to_numpy(dtype='float32')\n",
    "y_pbcl2_dset = pbcl2_dset.iloc[:,0].to_numpy(dtype='int64') \n",
    "\n",
    "X_pbno32_dset = pbno32_dset.iloc[:, 1:].to_numpy(dtype='float32')\n",
    "y_pbno32_dset = pbno32_dset.iloc[:,0].to_numpy(dtype='int64') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.4 train and test split for Classical Learner\n",
    "X_cdcl2_train, X_cdcl2_test, y_cdcl2_train, y_cdcl2_test = train_test_split(X_cdcl2_dset, y_cdcl2_dset, test_size = 0.2, \n",
    "                                                    random_state=123)\n",
    "\n",
    "X_pbcl2_train, X_pbcl2_test, y_pbcl2_train, y_pbcl2_test = train_test_split(X_pbcl2_dset, y_pbcl2_dset, test_size = 0.2, \n",
    "                                                    random_state=123)\n",
    "\n",
    "X_pbno32_train, X_pbno32_test, y_pbno32_train, y_pbno32_test = train_test_split(X_pbno32_dset, y_pbno32_dset, test_size = 0.2, \n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classical Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = BernoulliNB()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[361 149]\n",
      " [ 68 122]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.69\n",
      "BACC: 0.675\n",
      "F1: 0.529\n",
      "AUROC: 0.751\n",
      "AP: 0.441\n",
      "MCC: 0.319\n",
      "Precision: 0.45\n",
      "Recall: 0.642\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = BernoulliNB()\n",
    "scaler.fit(X_pbcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[524  68]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.903\n",
      "BACC: 0.943\n",
      "F1: 0.761\n",
      "AUROC: 0.944\n",
      "AP: 0.621\n",
      "MCC: 0.737\n",
      "Precision: 0.614\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = BernoulliNB()\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[490 102]\n",
      " [  5 103]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.847\n",
      "BACC: 0.891\n",
      "F1: 0.658\n",
      "AUROC: 0.91\n",
      "AP: 0.507\n",
      "MCC: 0.62\n",
      "Precision: 0.502\n",
      "Recall: 0.954\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"w\")\n",
    "outF.write(\"Naive_Bayes, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, NB_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, NB_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, NB_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cdcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = DecisionTreeClassifier()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[497  13]\n",
      " [ 10 180]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.967\n",
      "BACC: 0.961\n",
      "F1: 0.94\n",
      "AUROC: 0.961\n",
      "AP: 0.898\n",
      "MCC: 0.917\n",
      "Precision: 0.933\n",
      "Recall: 0.947\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pbcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = DecisionTreeClassifier()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = DecisionTreeClassifier()\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[589   3]\n",
      " [  4 104]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.99\n",
      "BACC: 0.979\n",
      "F1: 0.967\n",
      "AUROC: 0.979\n",
      "AP: 0.942\n",
      "MCC: 0.962\n",
      "Precision: 0.972\n",
      "Recall: 0.963\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"a\")\n",
    "outF.write(\"Decision_Tree, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, DT_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, DT_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, DT_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegression()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[504   6]\n",
      " [  0 190]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.991\n",
      "BACC: 0.994\n",
      "F1: 0.984\n",
      "AUROC: 1.0\n",
      "AP: 0.999\n",
      "MCC: 0.979\n",
      "Precision: 0.969\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pbcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegression()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegression()\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"a\")\n",
    "outF.write(\"Logistic_Regression, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LR_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LR_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LR_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Logistic Regression with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegressionCV()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[504   6]\n",
      " [  0 190]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.991\n",
      "BACC: 0.994\n",
      "F1: 0.984\n",
      "AUROC: 1.0\n",
      "AP: 0.999\n",
      "MCC: 0.979\n",
      "Precision: 0.969\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_CV_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pbcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegressionCV()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_CV_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
       "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = LogisticRegressionCV()\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_CV_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"a\")\n",
    "outF.write(\"Logistic_Regression_CV, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LR_CV_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LR_CV_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LR_CV_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[507   3]\n",
      " [  0 190]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.996\n",
      "BACC: 0.997\n",
      "F1: 0.992\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 0.989\n",
      "Precision: 0.984\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pbcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier()\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"a\")\n",
    "outF.write(\"MLP, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, MLP_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, MLP_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, MLP_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = RandomForestClassifier()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[507   3]\n",
      " [  0 190]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.996\n",
      "BACC: 0.997\n",
      "F1: 0.992\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 0.989\n",
      "Precision: 0.984\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pbcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = RandomForestClassifier()\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  1 107]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.999\n",
      "BACC: 0.995\n",
      "F1: 0.995\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 0.995\n",
      "Precision: 1.0\n",
      "Recall: 0.991\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = RandomForestClassifier()\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[591   1]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.999\n",
      "BACC: 0.999\n",
      "F1: 0.995\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 0.995\n",
      "Precision: 0.991\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"a\")\n",
    "outF.write(\"Random_Forest, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, RF_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, RF_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, RF_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = SVC(kernel = 'linear', probability=True)\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[507   3]\n",
      " [  1 189]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.994\n",
      "BACC: 0.994\n",
      "F1: 0.99\n",
      "AUROC: 0.999\n",
      "AP: 0.998\n",
      "MCC: 0.986\n",
      "Precision: 0.984\n",
      "Recall: 0.995\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVM_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pbcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = SVC(kernel = 'linear', probability=True)\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVM_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = SVC(kernel = 'linear', probability=True)\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinSVM_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"a\")\n",
    "outF.write(\"Linear_SVM, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LinSVM_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LinSVM_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, LinSVM_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = SVC(kernel = 'rbf', probability=True)\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_cdcl2_train)\n",
    "X_test_sds = scaler.transform(X_cdcl2_test)\n",
    "y_train = y_cdcl2_train\n",
    "y_test = y_cdcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[506   4]\n",
      " [  0 190]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.994\n",
      "BACC: 0.996\n",
      "F1: 0.99\n",
      "AUROC: 1.0\n",
      "AP: 0.999\n",
      "MCC: 0.986\n",
      "Precision: 0.979\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFSVM_cdcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pbcl2 Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = SVC(kernel = 'rbf', probability=True)\n",
    "scaler.fit(X_cdcl2_train)\n",
    "X_train_sds = scaler.transform(X_pbcl2_train)\n",
    "X_test_sds = scaler.transform(X_pbcl2_test)\n",
    "y_train = y_pbcl2_train\n",
    "y_test = y_pbcl2_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  1 107]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 0.999\n",
      "BACC: 0.995\n",
      "F1: 0.995\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 0.995\n",
      "Precision: 1.0\n",
      "Recall: 0.991\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFSVM_pbcl2_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn Classifier\n",
    "scaler = StandardScaler()\n",
    "clf = SVC(kernel = 'rbf', probability=True)\n",
    "scaler.fit(X_pbno32_train)\n",
    "X_train_sds = scaler.transform(X_pbno32_train)\n",
    "X_test_sds = scaler.transform(X_pbno32_test)\n",
    "y_train = y_pbno32_train\n",
    "y_test = y_pbno32_test\n",
    "clf.fit(X_train_sds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "[[592   0]\n",
      " [  0 108]]\n",
      "\u001b[1mMetrics\u001b[0m\n",
      "ACC: 1.0\n",
      "BACC: 1.0\n",
      "F1: 1.0\n",
      "AUROC: 1.0\n",
      "AP: 1.0\n",
      "MCC: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Test within batch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, f1_score \n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, matthews_corrcoef, average_precision_score\n",
    "\n",
    "yp_test = clf.predict(X_test_sds)\n",
    "ys_test = clf.predict_proba(X_test_sds)\n",
    "ys_test = ys_test[:,1]\n",
    "\n",
    "print('\\033[1m' + 'Confusion Matrix' + '\\033[0m')\n",
    "print(confusion_matrix(y_test, yp_test))\n",
    "\n",
    "print('\\033[1m' + 'Metrics' + '\\033[0m')\n",
    "print('ACC: {}'.format(round(accuracy_score(y_test, yp_test), 3)))\n",
    "print('BACC: {}'.format(round(balanced_accuracy_score(y_test, yp_test), 3)))\n",
    "print('F1: {}'.format(round(f1_score(y_test, yp_test),3)))\n",
    "print('AUROC: {}'.format(round(roc_auc_score(y_test, ys_test),3)))\n",
    "print('AP: {}'.format(round(average_precision_score(y_test, ys_test),3)))\n",
    "print('MCC: {}'.format(round(matthews_corrcoef(y_test, yp_test),3)))\n",
    "print('Precision: {}'.format(round(precision_score(y_test, yp_test),3)))\n",
    "print('Recall: {}'.format(round(recall_score(y_test, yp_test),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBFSVM_pbno32_devset_res = [round(accuracy_score(y_test, yp_test), 3), round(balanced_accuracy_score(y_test, yp_test), 3),\n",
    "                 round(f1_score(y_test, yp_test),3), round(roc_auc_score(y_test, ys_test),3),\n",
    "                 round(average_precision_score(y_test, ys_test),3), round(matthews_corrcoef(y_test, yp_test),3),\n",
    "                 round(precision_score(y_test, yp_test),3), round(recall_score(y_test, yp_test),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "outF = open(fileout, \"a\")\n",
    "outF.write(\"RBF_SVM, \")\n",
    "outF.write(\"ACC, BACC, F1, AUROC, Average_Precision, MCC, Precision, Recall\\n\")\n",
    "outF.write('Cdcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, RBFSVM_cdcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pbcl2 DevSet, ')\n",
    "outF.write(', '.join(map(str, RBFSVM_pbcl2_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.write('Pb(No3)2 DevSet, ')\n",
    "outF.write(', '.join(map(str, RBFSVM_pbno32_devset_res)))\n",
    "outF.write('\\n')\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
